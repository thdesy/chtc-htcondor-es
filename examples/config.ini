# Sample configuration file
# Modify then run "spider --config=/path/to/config.ini"
# Uses INI-style syntax, see https://docs.python.org/3/library/configparser.html

[COLLECTORS]
# List of Collectors that should be queried for the location of Schedds.
# Each Collector address must be on its own line.
#cm.mypool.org

[SCHEDDS]
# List of Schedds that should be queried.
# Each Schedd name should be on its own line.
# If no Schedds are defined here, all Schedds located by the Collectors will
# be queried.
#submit1.mypool.org
#submit2.mypool.org

[PROCESS]
#schedd_history = True
#schedd_queue = False

# Process at most $(max_documents) per Schedd, 0 [default] = process all documents.
#max_documents = 0

# Use multithreading to query $(parallel_queries) Schedds at the same time.
#parallel_queries = 8

[ELASTICSEARCH]
#host = es.mypool.org
#port = 9200
#username = esuser
#password = changeme
#bunch_size = 250

#feed_schedd_history = False
#feed_schedd_queue = False

# Documents are placed in indexes named $(index_name)-YYYY-MM-DD (shard per day)
# with the date generated from $(index_date_attr) ("CompletionDate" by default)
#index_name = htcondor_jobs
#index_date_attr = CompletionDate
